{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select\n",
    "import os\n",
    "import json\n",
    "from tca.database.models import (\n",
    "    DocumentChunk,\n",
    "    OpenAITextEmbedding3LargeChunkEmbedding,\n",
    "    OpenAITextEmbedding3LargeThemeEmbedding,\n",
    "    Theme,\n",
    ")\n",
    "from tca.database.session_manager import PostgresSessionManager\n",
    "from sqlalchemy import func\n",
    "import pandas as pd\n",
    "from tca.text.llm_clients import OpenAIAPIClient\n",
    "from typing import List, Dict, Any, Set, Tuple\n",
    "\n",
    "postgres_session_manager = PostgresSessionManager()\n",
    "session = postgres_session_manager.session\n",
    "\n",
    "llm_client = OpenAIAPIClient(\n",
    "    model_name=os.environ[\"OPENAI_LLM_MODEL\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")\n",
    "# llm_client = OllamaAPIClient(\n",
    "#     endpoint=Url(\"http://localhost:11434/api/generate\"),\n",
    "#     model_name=\"llama3.1:8b-instruct-fp16\",\n",
    "#     timeout=60,\n",
    "# )\n",
    "\n",
    "NB_CHUNKS_TO_RETRIEVE = 6\n",
    "\n",
    "query = select(\n",
    "    Theme,\n",
    "    OpenAITextEmbedding3LargeThemeEmbedding.embeddings,\n",
    ").join(Theme, OpenAITextEmbedding3LargeThemeEmbedding.theme_id == Theme.id)\n",
    "theme_with_embeddings = [\n",
    "    (theme, embeddings) for theme, embeddings in session.execute(query).all()\n",
    "]\n",
    "\n",
    "\n",
    "def find_themes_in_documents(\n",
    "    theme_with_embeddings: list[Tuple[Theme, Any]],\n",
    "    session: Any,\n",
    "    llm_client: Any,\n",
    "    nb_chunks_to_retrieve: int = NB_CHUNKS_TO_RETRIEVE,\n",
    ") -> pd.DataFrame:\n",
    "    theme_list: List[str] = []\n",
    "    doc_sentences: Dict[str, Set[str]] = {}\n",
    "\n",
    "    theme2_to_theme_info = {}\n",
    "    for theme_info, query_embeddings in theme_with_embeddings:\n",
    "        theme: str = theme_info.themes[-1]\n",
    "        theme2_to_theme_info[theme] = theme_info\n",
    "        theme_list.append(f\"{theme} : {theme_info.description}\")\n",
    "\n",
    "        chunk_select_query = (\n",
    "            select(\n",
    "                DocumentChunk,\n",
    "                OpenAITextEmbedding3LargeChunkEmbedding.embeddings.cosine_distance(\n",
    "                    query_embeddings\n",
    "                ).label(\"cos_distance\"),\n",
    "                func.row_number()\n",
    "                .over(\n",
    "                    partition_by=DocumentChunk.document_id,\n",
    "                    order_by=OpenAITextEmbedding3LargeChunkEmbedding.embeddings.cosine_distance(\n",
    "                        query_embeddings\n",
    "                    ),\n",
    "                )\n",
    "                .label(\"row_number\"),\n",
    "            )\n",
    "            .join(\n",
    "                OpenAITextEmbedding3LargeChunkEmbedding,\n",
    "                OpenAITextEmbedding3LargeChunkEmbedding.chunk_id == DocumentChunk.id,\n",
    "            )\n",
    "            .filter(\n",
    "                OpenAITextEmbedding3LargeChunkEmbedding.embeddings.cosine_distance(\n",
    "                    query_embeddings\n",
    "                )\n",
    "                < 0.75\n",
    "            )\n",
    "            .subquery()\n",
    "        )\n",
    "\n",
    "        query = (\n",
    "            select(\n",
    "                chunk_select_query.c.document_id,\n",
    "                func.array_agg(chunk_select_query.c.chunk_text).label(\"chunk_texts\"),\n",
    "                func.array_agg(chunk_select_query.c.cos_distance).label(\n",
    "                    \"cos_distances\"\n",
    "                ),\n",
    "            )\n",
    "            .filter(chunk_select_query.c.row_number <= nb_chunks_to_retrieve)\n",
    "            .group_by(chunk_select_query.c.document_id)\n",
    "            .order_by(func.min(chunk_select_query.c.cos_distance))\n",
    "        )\n",
    "\n",
    "        results = session.execute(query).all()\n",
    "\n",
    "        for document_id, chunk_texts, _cos_distances in results:\n",
    "            doc_sentences.setdefault(document_id, set()).update(chunk_texts)\n",
    "\n",
    "    themes_str: str = \"\\n- \".join(theme_list)\n",
    "    found_themes_per_doc: Dict[str, Dict[str, str]] = {}\n",
    "\n",
    "    results = []\n",
    "    for document_id, sentences in doc_sentences.items():\n",
    "        print(f\"document_id {document_id}\")\n",
    "        sentences_str: str = \"\\n- \".join(sentences)\n",
    "        prompt: str = f\"\"\"\n",
    "Je souhaite déterminer si les thèmes suivants sont abordés explicitement dans un accord d'entreprise.\n",
    "Les thèmes sont les suivants, avec la forme \"theme : description du thème\" :\n",
    "- {themes_str}\n",
    "\n",
    "Ces phrases proviennent de l'accord d'entreprise :\n",
    "\n",
    "- {sentences_str}\n",
    "\n",
    "Garde chaque thème qui est abordé explicitement en positif ou en négatif dans au moins une des phrases et ignore les autres thèmes.\n",
    "Retourne le résultat sous forme de JSON (sans balises de bloc de code) avec le format suivant :\n",
    "\n",
    "[\"theme1\", \"theme2\", ...]\n",
    "        \"\"\"\n",
    "        response: str = llm_client.generate_text(prompt)\n",
    "        response_obj = json.loads(response)\n",
    "        for theme in response_obj:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Document\": document_id,\n",
    "                    \"Thème n1\": theme2_to_theme_info[theme].themes[0],\n",
    "                    \"Thème n2\": theme2_to_theme_info[theme].themes[1],\n",
    "                }\n",
    "            )\n",
    "        found_themes_per_doc[document_id] = response_obj\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "found_themes_per_doc = find_themes_in_documents(\n",
    "    theme_with_embeddings=theme_with_embeddings,\n",
    "    session=session,\n",
    "    llm_client=llm_client,\n",
    "    nb_chunks_to_retrieve=NB_CHUNKS_TO_RETRIEVE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\n",
    "    json.dumps(\n",
    "        found_themes_per_doc[\n",
    "            \"1d6937456045163545c4d5d7cf65178c9e7b1ea96922a36727abd4afe3733b7b\"\n",
    "        ],\n",
    "        indent=4,\n",
    "        ensure_ascii=False,\n",
    "    )\n",
    ")\n",
    "result = {\n",
    "    \"salaires\": \"Amélioration des conditions salariales mentionnée.\",\n",
    "    \"commissions\": \"Création d'une commission ad hoc mentionnée.\",\n",
    "    \"fin de conflit\": \"Protocole de fin de conflit mentionné.\",\n",
    "    \"indemnités\": \"Conditions d'accès à l'indemnité des paniers repas mentionnées.\",\n",
    "    \"droit syndical irp & expression des salariés\": \"Participation des organisations syndicales CGT et STC mentionnée.\",\n",
    "    \"dispositions conditions de travail\": \"Conditions de travail et plannings d'intervention mentionnés.\",\n",
    "    \"déplacement\": \"Temps de déplacement considéré comme temps de travail effectif mentionné.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tca.database.models import DocumentChunk\n",
    "from tca.database.models import (\n",
    "    DocumentChunk,\n",
    ")\n",
    "from tca.database.session_manager import PostgresSessionManager\n",
    "\n",
    "postgres_session_manager = PostgresSessionManager()\n",
    "session = postgres_session_manager.session\n",
    "doc_id = \"1d6937456045163545c4d5d7cf65178c9e7b1ea96922a36727abd4afe3733b7b\"\n",
    "document = session.query(DocumentChunk).filter_by(document_id=doc_id).first()\n",
    "if document:\n",
    "    print(document.document_name)\n",
    "else:\n",
    "    print(f\"No document found with id {doc_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
